{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiohsst/LinkPredictionGNN/blob/main/link_prediction_heterogeneous_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** Fabio Tavares\n",
        "\n",
        "**Email:** fabio.tavares.fma@gmail.com\n",
        "\n",
        "**LinkedIn:** [Fabiohsst](https://www.linkedin.com/in/fabiohsst/)"
      ],
      "metadata": {
        "id": "lxYI6bOTsC7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing required packages"
      ],
      "metadata": {
        "id": "lvaw9VxUsLYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh7LaSzfwcj2",
        "outputId": "b7dd0da5-431e-4a18-b376-de257d2142bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsWUrVh7vZtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6325d9d0-9b81-4cd7-d4f7-37e30f50aca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.1+pt20cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.17+pt20cu118\n",
            "Looking in links: https://data.pyg.org/whl/nightly/torch-2.0.1+cu118.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/nightly/torch-2.0.0%2Bcu118/pyg_lib-0.2.0.dev20230827%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyg-lib\n",
            "Successfully installed pyg-lib-0.2.0.dev20230827+pt20cu118\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-55ysinzj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-55ysinzj\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 143487bc18a5bf3e7968c2637823791781e6135a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=986643 sha256=c0415d54386768443a410690567322e402256082cf5467033e33a8a9eca4ff4f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-smvt4za8/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heterogeneous Graph Creation\n"
      ],
      "metadata": {
        "id": "N_pshZh8Y3dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import datasets\n",
        "import pandas as pd\n",
        "\n",
        "# Defines columns name\n",
        "column_names = [\"userid\", \"timestamp\", \"artistid\", \"artist-name\", \"trackid\", \"track-name\"]\n",
        "\n",
        "# Load songs dataset\n",
        "songs = pd.read_csv('/content/drive/MyDrive/Thesis/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv',\n",
        "                    sep='\\t',names=column_names, error_bad_lines=False)\n",
        "\n",
        "# Load users dataset\n",
        "users = pd.read_csv('/content/drive/MyDrive/Thesis/lastfm-dataset-1K/userid-profile.tsv', sep='\\t', error_bad_lines=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciYr7NWEv5_o",
        "outputId": "95fe4a52-96cc-4e59-8ab1-705f185e9652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-0a89e584a9d5>:8: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  songs = pd.read_csv('/content/drive/MyDrive/Thesis/lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv',\n",
            "Skipping line 2120260: expected 6 fields, saw 8\n",
            "\n",
            "Skipping line 2446318: expected 6 fields, saw 8\n",
            "\n",
            "Skipping line 11141081: expected 6 fields, saw 8\n",
            "\n",
            "Skipping line 11152099: expected 6 fields, saw 12\n",
            "Skipping line 11152402: expected 6 fields, saw 8\n",
            "\n",
            "Skipping line 11882087: expected 6 fields, saw 8\n",
            "\n",
            "Skipping line 12902539: expected 6 fields, saw 8\n",
            "Skipping line 12935044: expected 6 fields, saw 8\n",
            "\n",
            "Skipping line 17589539: expected 6 fields, saw 8\n",
            "\n",
            "<ipython-input-5-0a89e584a9d5>:12: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  users = pd.read_csv('/content/drive/MyDrive/Thesis/lastfm-dataset-1K/userid-profile.tsv', sep='\\t', error_bad_lines=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print songs and users dataset\n",
        "print('songs:')\n",
        "print('===========')\n",
        "print(songs.head())\n",
        "print()\n",
        "print('users:')\n",
        "print('============')\n",
        "print(users.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6ixkcCOwCDi",
        "outputId": "f842f866-c5a5-4aae-a084-b62b722592c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "songs:\n",
            "===========\n",
            "        userid             timestamp                              artistid  \\\n",
            "0  user_000001  2009-05-04T23:08:57Z  f1b1cf71-bd35-4e99-8624-24a6e15f133a   \n",
            "1  user_000001  2009-05-04T13:54:10Z  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
            "2  user_000001  2009-05-04T13:52:04Z  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
            "3  user_000001  2009-05-04T13:42:52Z  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
            "4  user_000001  2009-05-04T13:42:11Z  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
            "\n",
            "  artist-name trackid                                  track-name  \n",
            "0   Deep Dish     NaN  Fuck Me Im Famous (Pacha Ibiza)-09-28-2007  \n",
            "1        坂本龍一     NaN           Composition 0919 (Live_2009_4_15)  \n",
            "2        坂本龍一     NaN                        Mc2 (Live_2009_4_15)  \n",
            "3        坂本龍一     NaN                     Hibari (Live_2009_4_15)  \n",
            "4        坂本龍一     NaN                        Mc1 (Live_2009_4_15)  \n",
            "\n",
            "users:\n",
            "============\n",
            "           #id gender   age        country    registered\n",
            "0  user_000001      m   NaN          Japan  Aug 13, 2006\n",
            "1  user_000002      f   NaN           Peru  Feb 24, 2006\n",
            "2  user_000003      m  22.0  United States  Oct 30, 2005\n",
            "3  user_000004      f   NaN            NaN  Apr 26, 2006\n",
            "4  user_000005      m   NaN       Bulgaria  Jun 29, 2006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning and Feature engineering"
      ],
      "metadata": {
        "id": "sKnByfHzE5cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove missing values on 'songs' dataset\n",
        "songs.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "YSaA4wwlE463"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values on users dataset\n",
        "\n",
        "# For numerical columns\n",
        "mean_age = users['age'].mean()\n",
        "mean_age_rounded = round(mean_age)\n",
        "users['age'].fillna(mean_age_rounded, inplace=True)\n",
        "users['age'] = users['age'].astype(int)\n",
        "\n",
        "# Missing gender\n",
        "users['gender'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Missing Country\n",
        "users['country'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Drop remaining missing values\n",
        "users.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "NjiYuz5cHOET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH8AHzfSMVWj",
        "outputId": "73a81710-b902-407e-cb9b-7ea876bfd80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "#id           object\n",
              "gender        object\n",
              "age            int64\n",
              "country       object\n",
              "registered    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Double check missing values\n",
        "missing_values_songs = songs.isnull().sum()\n",
        "missing_values_users = users.isnull().sum()\n",
        "\n",
        "print('songs missings values:')\n",
        "print(missing_values_songs)\n",
        "print('======================')\n",
        "print('users missings values:')\n",
        "print(missing_values_users)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ugGoG_nHf7_",
        "outputId": "05338f89-50e4-4622-da94-69aec36b0461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "songs missings values:\n",
            "userid         0\n",
            "timestamp      0\n",
            "artistid       0\n",
            "artist-name    0\n",
            "trackid        0\n",
            "track-name     0\n",
            "dtype: int64\n",
            "======================\n",
            "users missings values:\n",
            "#id           0\n",
            "gender        0\n",
            "age           0\n",
            "country       0\n",
            "registered    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling dataset"
      ],
      "metadata": {
        "id": "vF6w8WmxIHUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sample users\n",
        "sampled_users = users.sample(frac=0.2, random_state=42)\n",
        "\n",
        "# 2. Use the sampled users to filter the songs dataset.\n",
        "sampled_songs_data = songs[songs['userid'].isin(sampled_users['#id'])]\n",
        "\n",
        "# 3. Sample the songs dataset\n",
        "sampled_songs_data = sampled_songs_data.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# 4. Filter the users dataset to include only users present in the sampled_songs_data\n",
        "final_users = sampled_users[sampled_users['#id'].isin(sampled_songs_data['userid'])]"
      ],
      "metadata": {
        "id": "sHI__h00IQqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creates new feature for tracks"
      ],
      "metadata": {
        "id": "xU_T30ULFRMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'timestamp' column to datetime format\n",
        "sampled_songs_data['timestamp'] = pd.to_datetime(sampled_songs_data['timestamp'])\n",
        "\n",
        "# Convert the 'registered' column to datetime format and coerce any errors\n",
        "final_users['registered'] = pd.to_datetime(users['registered'], errors='coerce')\n",
        "\n",
        "# Assuming first timestamp as \"release date\"\n",
        "song_release_date = sampled_songs_data.groupby('track-name')['timestamp'].min()\n",
        "sampled_songs_data['song_release_date'] = sampled_songs_data['track-name'].map(song_release_date)\n",
        "sampled_songs_data['days_since_release'] = (sampled_songs_data['timestamp'] - sampled_songs_data['song_release_date']).dt.days\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwps7nc5FLg7",
        "outputId": "01f2e3c5-7d0b-4b53-8cb5-e1a2d1b7f0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a8b139a86963>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_users['registered'] = pd.to_datetime(users['registered'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print datasets shape\n",
        "print(f'Users sampled shape:{final_users.shape}')\n",
        "print(f'Songs sampled shape:{sampled_songs_data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCUdLOqVKz8I",
        "outputId": "563378ee-ba54-4768-d55f-72db0862a147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users sampled shape:(196, 5)\n",
            "Songs sampled shape:(340364, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check songs columns\n",
        "sampled_songs_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGfhkvqMSwvF",
        "outputId": "828cda90-e6d4-4535-f7ee-0def31a5ff97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['userid', 'timestamp', 'artistid', 'artist-name', 'trackid',\n",
              "       'track-name', 'song_release_date', 'days_since_release'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of unique countries, genders and age\n",
        "unique_countries = final_users['country'].unique()\n",
        "unique_genders = final_users['gender'].unique()\n",
        "age = final_users['age']\n",
        "\n",
        "print(f'Countries on the dataset:{unique_countries} a total of {unique_countries.size} countries')\n",
        "print('==================================================')\n",
        "print(f'Genders values on the dataset:{unique_genders}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "802W4DxyLnqk",
        "outputId": "abe2c708-bce2-4d76-862b-8e8e0f436a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Countries on the dataset:['Argentina' 'Canada' 'Unknown' 'Finland' 'United States' 'Netherlands'\n",
            " 'Norway' 'Sweden' 'Tunisia' 'Macedonia' 'Bulgaria' 'Czech Republic'\n",
            " 'Latvia' 'Australia' 'Japan' 'Germany' 'United Kingdom' 'Algeria'\n",
            " 'Poland' 'Turkey' 'Italy' 'Peru' 'Portugal' 'Brazil' 'Mexico'\n",
            " 'Antarctica' 'Estonia' 'Armenia' 'Belgium' 'Chile' 'New Zealand'\n",
            " 'Russian Federation' 'Lithuania' 'France' 'Greece' 'Trinidad and Tobago'\n",
            " 'Serbia' 'Spain' 'Slovakia' \"Korea, Democratic People's Republic of\"\n",
            " 'Romania' 'Slovenia' 'Colombia'] a total of 43 countries\n",
            "==================================================\n",
            "Genders values on the dataset:['m' 'f' 'Unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert columns to dummies values\n",
        "country_dummies = final_users['country'].str.get_dummies()\n",
        "gender_dummies = final_users['gender'].str.get_dummies()\n",
        "print(country_dummies[['Argentina', 'Canada', 'Unknown', 'Finland']].head())\n",
        "print()\n",
        "print('=======================================')\n",
        "print(gender_dummies.head())\n",
        "\n",
        "\n",
        "# Combine dummies and age columns\n",
        "combined_dummies = pd.concat([country_dummies, gender_dummies,age], axis=1)\n",
        "\n",
        "# User features\n",
        "users_feat = torch.from_numpy(combined_dummies.values).to(torch.float)\n",
        "assert users_feat.size() ==(196, 47)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50Cr8TZwPENs",
        "outputId": "15eae3f9-07b9-43ef-e0f4-60ef30ed9bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Argentina  Canada  Unknown  Finland\n",
            "618          1       0        0        0\n",
            "455          0       1        0        0\n",
            "737          0       0        1        0\n",
            "440          0       0        0        1\n",
            "278          0       0        0        0\n",
            "\n",
            "=======================================\n",
            "     Unknown  f  m\n",
            "618        0  0  1\n",
            "455        0  1  0\n",
            "737        0  0  1\n",
            "440        1  0  0\n",
            "278        0  1  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Track feature\n",
        "days_since_release = sampled_songs_data['days_since_release']\n",
        "track_feat = torch.from_numpy(days_since_release.values).to(torch.float)\n",
        "assert track_feat.size() ==(340364,)"
      ],
      "metadata": {
        "id": "QS5rxfIm1WRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ratings.csv` data connects users (as given by `userId`) and movies (as given by `movieId`).\n",
        "Due to simplicity, we do not make use of the additional `timestamp` and `rating` information.\n",
        "Here, we first read the `*.csv` file from disk, and create a mapping that maps entry IDs to a consecutive value in the range `{ 0, ..., num_rows - 1 }`.\n",
        "This is needed as we want our final data representation to be as compact as possible, *e.g.*, the representation of a movie in the first row should be accessible via `x[0]`.\n",
        "\n",
        "Afterwards, we obtain the final `edge_index` representation of shape `[2, num_ratings]` from `ratings.csv` by merging mapped user and movie indices with the raw indices given by the original data frame."
      ],
      "metadata": {
        "id": "KLaDBVP4plsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping unique IDs"
      ],
      "metadata": {
        "id": "0P9DUNhiBGTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from unique user indices to range [0, num_user_nodes):\n",
        "unique_user_id = sampled_songs_data['userid'].unique()\n",
        "unique_user_id = pd.DataFrame(data={\n",
        "    'userid': unique_user_id,\n",
        "    'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
        "})\n",
        "print(\"Mapping of user IDs to consecutive values:\")\n",
        "print(\"==========================================\")\n",
        "print(unique_user_id.head())\n",
        "print()\n",
        "\n",
        "# Create a mapping from unique track indices to range [0, num_track_nodes):\n",
        "unique_track_id = sampled_songs_data['trackid'].unique()\n",
        "unique_track_id = pd.DataFrame(data={\n",
        "    'trackid': unique_track_id,\n",
        "    'mappedID': pd.RangeIndex(len(unique_track_id)),\n",
        "})\n",
        "print(\"Mapping of track IDs to consecutive values:\")\n",
        "print(\"===========================================\")\n",
        "print(unique_track_id.head())\n",
        "\n",
        "# Create a mapping from unique artist indices to range [0, num_artist_nodes):\n",
        "unique_artist_id = sampled_songs_data['artistid'].unique()\n",
        "unique_artist_id = pd.DataFrame(data={\n",
        "    'artistid': unique_artist_id,\n",
        "    'mappedID': pd.RangeIndex(len(unique_artist_id)),\n",
        "})\n",
        "print(\"Mapping of artist IDs to consecutive values:\")\n",
        "print(\"===========================================\")\n",
        "print(unique_artist_id.head())\n",
        "\n",
        "# Perform merge to obtain the edges from users and tracks:\n",
        "user_id = pd.merge(sampled_songs_data['userid'], unique_user_id,\n",
        "                            left_on='userid', right_on='userid', how='left')\n",
        "user_id = torch.from_numpy(user_id['mappedID'].values)\n",
        "track_id = pd.merge(sampled_songs_data['trackid'], unique_track_id,\n",
        "                            left_on='trackid', right_on='trackid', how='left')\n",
        "track_id = torch.from_numpy(track_id['mappedID'].values)\n",
        "artist_id = pd.merge(sampled_songs_data['artistid'], unique_artist_id,\n",
        "                            left_on='artistid', right_on='artistid', how='left')\n",
        "artist_id = torch.from_numpy(artist_id['mappedID'].values)\n",
        "\n",
        "# construct `edge_index` in COO format\n",
        "# following PyG semantics:\n",
        "edge_index_user_to_track = torch.stack([user_id, track_id], dim=0)\n",
        "assert edge_index_user_to_track.size() == (2, 340364)\n",
        "edge_index_user_to_artist = torch.stack([user_id, artist_id], dim=0)\n",
        "assert edge_index_user_to_artist.size() == (2, 340364)\n",
        "\n",
        "print()\n",
        "print(\"Final edge indices pointing from users to tracks:\")\n",
        "print(\"=================================================\")\n",
        "print(edge_index_user_to_track)\n",
        "print()\n",
        "print(\"Final edge indices pointing from users to artists:\")\n",
        "print(\"=================================================\")\n",
        "print(edge_index_user_to_track)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMGYv83WzSRr",
        "outputId": "d0929059-557e-4718-9c77-7d2f5d202a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of user IDs to consecutive values:\n",
            "==========================================\n",
            "        userid  mappedID\n",
            "0  user_000188         0\n",
            "1  user_000142         1\n",
            "2  user_000748         2\n",
            "3  user_000329         3\n",
            "4  user_000792         4\n",
            "\n",
            "Mapping of track IDs to consecutive values:\n",
            "===========================================\n",
            "                                trackid  mappedID\n",
            "0  423672d5-14e9-4068-b198-8e5724e7342c         0\n",
            "1  618566d5-2ff5-4388-8947-03ceba773483         1\n",
            "2  82e9a44d-6c71-4bcd-9719-7dfdfe8ede41         2\n",
            "3  24436eea-e79f-4592-b7f8-3e9bfe01f483         3\n",
            "4  f073f081-d9ad-4b1f-9789-070d07481eb5         4\n",
            "Mapping of artist IDs to consecutive values:\n",
            "===========================================\n",
            "                               artistid  mappedID\n",
            "0  5e521e8c-0ab2-44c4-8fd8-14d8d3321265         0\n",
            "1  c707b37e-cb5c-4694-be4d-46beefcb2475         1\n",
            "2  3525b27c-e5a5-4d1c-b80b-f223696bf675         2\n",
            "3  c485632c-b784-4ee9-8ea1-c5fb365681fc         3\n",
            "4  7d31729b-4a6e-422a-9919-eb225a511fb0         4\n",
            "\n",
            "Final edge indices pointing from users to tracks:\n",
            "=================================================\n",
            "tensor([[     0,      1,      2,  ...,     36,     22,     90],\n",
            "        [     0,      1,      2,  ..., 137054,   9992,  12671]])\n",
            "\n",
            "Final edge indices pointing from users to artists:\n",
            "=================================================\n",
            "tensor([[     0,      1,      2,  ...,     36,     22,     90],\n",
            "        [     0,      1,      2,  ..., 137054,   9992,  12671]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link Prediction: Users and tracks"
      ],
      "metadata": {
        "id": "2IPv-TGMJYth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create heterogeneous graph with HeteroData - Users and Tracks interaction"
      ],
      "metadata": {
        "id": "paQVcbwIBTI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "data_track = HeteroData()\n",
        "\n",
        "# Save node indices:\n",
        "data_track[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
        "data_track[\"track\"].node_id = torch.arange(len(sampled_songs_data))\n",
        "\n",
        "# Add the node features and edge indices:\n",
        "data_track[\"user\"].x = users_feat\n",
        "data_track[\"track\"].x = track_feat\n",
        "data_track[\"user\", \"listened_to\", \"track\"].edge_index = edge_index_user_to_track\n",
        "\n",
        "# Add reverse edges using `T.ToUndirected()`\n",
        "data_track = T.ToUndirected()(data_track)\n",
        "\n",
        "print(data_track)\n",
        "\n",
        "assert data_track.node_types == [\"user\", \"track\"]\n",
        "assert data_track.edge_types == [(\"user\", \"listened_to\", \"track\"),\n",
        "                           (\"track\", \"rev_listened_to\", \"user\")]\n",
        "assert data_track[\"user\"].num_nodes == 196\n",
        "assert data_track[\"user\"].num_features == 47\n",
        "assert data_track[\"track\"].num_nodes == 340364\n",
        "assert data_track[\"track\"].num_features == 1\n",
        "assert data_track[\"user\", \"listened_to\", \"track\"].num_edges == 340364\n",
        "assert data_track[\"track\", \"rev_listened_to\", \"user\"].num_edges == 340364"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1y-woFDH591",
        "outputId": "74e27d37-9c3a-41b1-8b31-4e507aa90dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[196],\n",
            "    x=[196, 47],\n",
            "  },\n",
            "  track={\n",
            "    node_id=[340364],\n",
            "    x=[340364],\n",
            "  },\n",
            "  (user, listened_to, track)={ edge_index=[2, 340364] },\n",
            "  (track, rev_listened_to, user)={ edge_index=[2, 340364] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Edge-level Training Splits\n"
      ],
      "metadata": {
        "id": "2QGdkLAurBq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the set of edges into\n",
        "# training (80%), validation (10%), and testing edges (10%).\n",
        "# Across the training edges, 70% of edges is used for message passing,\n",
        "# and 30% of edges for supervision.\n",
        "# Generate fixed negative edges for evaluation with a ratio of 2:1.\n",
        "# Negative edges during training will be generated on-the-fly.\n",
        "\n",
        "# Leverage the `RandomLinkSplit()` transform for this from PyG:\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    disjoint_train_ratio=0.3,\n",
        "    neg_sampling_ratio=2.0,\n",
        "    add_negative_train_samples=False,\n",
        "    edge_types=(\"user\", \"listened_to\", \"track\"),\n",
        "    rev_edge_types=(\"track\", \"rev_listened_to\", \"user\")\n",
        ")\n",
        "\n",
        "train_data, val_data, test_data = transform(data_track)\n",
        "print(\"Training data:\")\n",
        "print(\"==============\")\n",
        "print(train_data)\n",
        "print()\n",
        "print(\"Validation data:\")\n",
        "print(\"================\")\n",
        "print(val_data)\n",
        "\n",
        "assert train_data[\"user\", \"listened_to\", \"track\"].num_edges == 190605\n",
        "assert train_data[\"user\", \"listened_to\", \"track\"].edge_label_index.size(1) == 81687\n",
        "assert train_data[\"track\", \"rev_listened_to\", \"user\"].num_edges == 190605\n",
        "# No negative edges added:\n",
        "assert train_data[\"user\", \"listened_to\", \"track\"].edge_label.min() == 1\n",
        "assert train_data[\"user\", \"listened_to\", \"track\"].edge_label.max() == 1\n",
        "\n",
        "assert val_data[\"user\", \"listened_to\", \"track\"].num_edges == 272292\n",
        "assert val_data[\"user\", \"listened_to\", \"track\"].edge_label_index.size(1) == 102108\n",
        "assert val_data[\"track\", \"rev_listened_to\", \"user\"].num_edges == 272292\n",
        "# Negative edges with ratio 2:1:\n",
        "assert val_data[\"user\", \"listened_to\", \"track\"].edge_label.long().bincount().tolist() == [68072, 34036]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwgNwoa26Eja",
        "outputId": "42415d86-98c1-4921-b46c-1e4475c46b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data:\n",
            "==============\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[196],\n",
            "    x=[196, 47],\n",
            "  },\n",
            "  track={\n",
            "    node_id=[340364],\n",
            "    x=[340364],\n",
            "  },\n",
            "  (user, listened_to, track)={\n",
            "    edge_index=[2, 190605],\n",
            "    edge_label=[81687],\n",
            "    edge_label_index=[2, 81687],\n",
            "  },\n",
            "  (track, rev_listened_to, user)={ edge_index=[2, 190605] }\n",
            ")\n",
            "\n",
            "Validation data:\n",
            "================\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[196],\n",
            "    x=[196, 47],\n",
            "  },\n",
            "  track={\n",
            "    node_id=[340364],\n",
            "    x=[340364],\n",
            "  },\n",
            "  (user, listened_to, track)={\n",
            "    edge_index=[2, 272292],\n",
            "    edge_label=[102108],\n",
            "    edge_label_index=[2, 102108],\n",
            "  },\n",
            "  (track, rev_listened_to, user)={ edge_index=[2, 272292] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Mini-batch Loaders"
      ],
      "metadata": {
        "id": "prKLwq6RsYoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the first hop, we sample at most 20 neighbors.\n",
        "# firs hop: 20 neighbours\n",
        "# In the second hop, we sample at most 10 neighbors.\n",
        "# second hop: 10 neighbours\n",
        "# During training, negative edges are sampled on-the-fly with a ratio of 2:1.\n",
        "\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "\n",
        "# Define seed edges:\n",
        "edge_label_index = train_data[\"user\", \"listened_to\", \"track\"].edge_label_index\n",
        "edge_label = train_data[\"user\", \"listened_to\", \"track\"].edge_label\n",
        "\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,\n",
        "    num_neighbors=[20, 10],\n",
        "    neg_sampling_ratio=2.0,\n",
        "    edge_label_index=((\"user\", \"listened_to\", \"track\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Inspect a sample:\n",
        "sampled_data = next(iter(train_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data[\"user\", \"listened_to\", \"track\"].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data[\"user\", \"listened_to\", \"track\"].edge_label.min() == 0\n",
        "assert sampled_data[\"user\", \"listened_to\", \"track\"].edge_label.max() == 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogh615ka9I2c",
        "outputId": "ff61708a-804d-46ca-fe9c-d58230ecd0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[194],\n",
            "    x=[194, 47],\n",
            "    n_id=[194],\n",
            "    num_sampled_nodes=[3],\n",
            "  },\n",
            "  track={\n",
            "    node_id=[3644],\n",
            "    x=[3644],\n",
            "    n_id=[3644],\n",
            "    num_sampled_nodes=[3],\n",
            "  },\n",
            "  (user, listened_to, track)={\n",
            "    edge_index=[2, 11563],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    e_id=[11563],\n",
            "    num_sampled_edges=[2],\n",
            "    input_id=[128],\n",
            "  },\n",
            "  (track, rev_listened_to, user)={\n",
            "    edge_index=[2, 3387],\n",
            "    e_id=[3387],\n",
            "    num_sampled_edges=[2],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Heterogeneous Link-level GNN\n"
      ],
      "metadata": {
        "id": "uj7biOtatAmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, x_track: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_track = x_track[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return (edge_feat_user * edge_feat_track).sum(dim=-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.track_lin = torch.nn.Linear(1, hidden_channels)\n",
        "        self.user_lin = torch.nn.Linear(47, hidden_channels)\n",
        "        self.track_emb = torch.nn.Embedding(data_track[\"track\"].num_nodes, hidden_channels)\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data_track.metadata())\n",
        "\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"user\": self.user_lin(data[\"user\"].x),\n",
        "          \"track\": self.track_lin(data[\"track\"].x.view(-1, 1)) + self.track_emb(data[\"track\"].node_id),\n",
        "        }\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"user\"],\n",
        "            x_dict[\"track\"],\n",
        "            data[\"user\", \"listened_to\", \"track\"].edge_label_index,\n",
        "        )\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "model = Model(hidden_channels=64)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebsFf-Pr_4LF",
        "outputId": "a4163fdd-07b0-4db0-9247-709bda89a206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (track_lin): Linear(in_features=1, out_features=64, bias=True)\n",
            "  (user_lin): Linear(in_features=47, out_features=64, bias=True)\n",
            "  (track_emb): Embedding(340364, 64)\n",
            "  (gnn): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (user__listened_to__track): SAGEConv(64, 64, aggr=mean)\n",
            "      (track__rev_listened_to__user): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (user__listened_to__track): SAGEConv(64, 64, aggr=mean)\n",
            "      (track__rev_listened_to__user): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Classifier()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Heterogeneous Link-level GNN"
      ],
      "metadata": {
        "id": "05dfew-WuWHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Delete later\n",
        "print(\"Shape of track.x:\", data_track[\"track\"].x.shape)\n",
        "print(\"Shape of track.node_id:\", data_track[\"track\"].node_id.shape)\n",
        "\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "\n",
        "        ground_truth = sampled_data[\"user\", \"listened_to\", \"track\"].edge_label\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqLuXEcrAMru",
        "outputId": "c5337943-5fac-4993-8e42-d5b4c677f71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: 'cuda'\n",
            "Shape of track.x: torch.Size([340364])\n",
            "Shape of track.node_id: torch.Size([340364])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:07<00:00, 85.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 235.4205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:07<00:00, 86.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 2.1514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:07<00:00, 86.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.9699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:07<00:00, 85.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.6433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:07<00:00, 87.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Loss: 0.5455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating Heterogeneous Link-level GNN\n"
      ],
      "metadata": {
        "id": "Yq-I2xaYueF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data[\"user\", \"listened_to\", \"track\"].edge_label_index\n",
        "edge_label = val_data[\"user\", \"listened_to\", \"track\"].edge_label\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,\n",
        "    num_neighbors=[20, 10],\n",
        "    edge_label_index=((\"user\", \"listened_to\", \"track\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "sampled_data = next(iter(val_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data[\"user\", \"listened_to\", \"track\"].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data[\"user\", \"listened_to\", \"track\"].edge_label.min() >= 0\n",
        "assert sampled_data[\"user\", \"listened_to\", \"track\"].edge_label.max() <= 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIrRn9YoNllj",
        "outputId": "1fb50290-9f47-4a70-d5e6-842391dccba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[183],\n",
            "    x=[183, 47],\n",
            "    n_id=[183],\n",
            "    num_sampled_nodes=[3],\n",
            "  },\n",
            "  track={\n",
            "    node_id=[3140],\n",
            "    x=[3140],\n",
            "    n_id=[3140],\n",
            "    num_sampled_nodes=[3],\n",
            "  },\n",
            "  (user, listened_to, track)={\n",
            "    edge_index=[2, 11847],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    e_id=[11847],\n",
            "    num_sampled_edges=[2],\n",
            "    input_id=[384],\n",
            "  },\n",
            "  (track, rev_listened_to, user)={\n",
            "    edge_index=[2, 2866],\n",
            "    e_id=[2866],\n",
            "    num_sampled_edges=[2],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        preds.append(model(sampled_data))\n",
        "        ground_truths.append(sampled_data[\"user\", \"listened_to\", \"track\"].edge_label)\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "\n",
        "# Calculate ROC-AUC\n",
        "auc = roc_auc_score(ground_truth, pred)\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n",
        "\n",
        "# Calculate Average Precision (AP)\n",
        "ap = average_precision_score(ground_truth, pred)\n",
        "print(f\"Average Precision (AP): {ap:.4f}\")\n",
        "\n",
        "# Calculate F1 score\n",
        "# First, we need to convert the probabilities to class labels (0 or 1)\n",
        "# We use 0.5 as the threshold\n",
        "pred_labels = (pred > 0.5).astype(int)\n",
        "f1 = f1_score(ground_truth, pred_labels)\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "Vi25Z7lFPPjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3cce650-8693-46b0-ebae-5b3bc77522ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 266/266 [00:05<00:00, 50.94it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation AUC: 0.7703\n",
            "Average Precision (AP): 0.6168\n",
            "F1 Score: 0.6258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link prediction: Users and Artists"
      ],
      "metadata": {
        "id": "bal2S2vWJzpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create heterogeneous graph with HeteroData - Users and artists interaction"
      ],
      "metadata": {
        "id": "ymgb_IsaJRaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define graph to user and artist interaction\n",
        "data_artist = HeteroData()\n",
        "\n",
        "# Save node indices:\n",
        "data_artist[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
        "data_artist[\"artist\"].node_id = torch.arange(len(sampled_songs_data))\n",
        "\n",
        "# Add the node features and edge indices:\n",
        "data_artist[\"user\"].x = users_feat\n",
        "data_artist[\"user\", \"listened_to_artist\", \"artist\"].edge_index = edge_index_user_to_artist\n",
        "\n",
        "# Add reverse edges using `T.ToUndirected()`\n",
        "data_artist = T.ToUndirected()(data_artist)\n",
        "\n",
        "print(data_artist)\n",
        "\n",
        "assert data_artist.node_types == [\"user\",\"artist\"]\n",
        "assert data_artist.edge_types == [(\"user\", \"listened_to_artist\", \"artist\"),\n",
        "                           (\"artist\", \"rev_listened_to_artist\", \"user\")]\n",
        "assert data_artist[\"user\"].num_nodes == 196\n",
        "assert data_artist[\"user\"].num_features == 47\n",
        "assert data_artist[\"artist\"].num_nodes == 340364\n",
        "assert data_artist[\"artist\"].num_features == 0\n",
        "assert data_artist[\"user\", \"listened_to_artist\", \"artist\"].num_edges == 340364\n",
        "assert data_artist[\"artist\", \"rev_listened_to_artist\", \"user\"].num_edges == 340364"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_63--974srt",
        "outputId": "62e2129a-afaa-4456-c2b5-65dcf042bf0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[196],\n",
            "    x=[196, 47],\n",
            "  },\n",
            "  artist={ node_id=[340364] },\n",
            "  (user, listened_to_artist, artist)={ edge_index=[2, 340364] },\n",
            "  (artist, rev_listened_to_artist, user)={ edge_index=[2, 340364] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Edge-level Training Splits\n"
      ],
      "metadata": {
        "id": "2OcLOvjINjiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the set of edges into\n",
        "# training (80%), validation (10%), and testing edges (10%).\n",
        "# Across the training edges, 70% of edges is used for message passing,\n",
        "# and 30% of edges for supervision.\n",
        "# Generate fixed negative edges for evaluation with a ratio of 2:1.\n",
        "# Negative edges during training will be generated on-the-fly.\n",
        "\n",
        "# Leverage the `RandomLinkSplit()` transform for this from PyG:\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    disjoint_train_ratio=0.3,\n",
        "    neg_sampling_ratio=2.0,\n",
        "    add_negative_train_samples=False,\n",
        "    edge_types=(\"user\", \"listened_to_artist\", \"artist\"),\n",
        "    rev_edge_types=(\"artist\", \"rev_listened_to_artist\", \"user\")\n",
        ")\n",
        "\n",
        "train_data, val_data, test_data = transform(data_artist)\n",
        "print(\"Training data:\")\n",
        "print(\"==============\")\n",
        "print(train_data)\n",
        "print()\n",
        "print(\"Validation data:\")\n",
        "print(\"================\")\n",
        "print(val_data)\n",
        "\n",
        "assert train_data[\"user\", \"listened_to_artist\", \"artist\"].num_edges == 190605\n",
        "assert train_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label_index.size(1) == 81687\n",
        "assert train_data[\"artist\", \"rev_listened_to_artist\", \"user\"].num_edges == 190605\n",
        "# No negative edges added:\n",
        "assert train_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label.min() == 1\n",
        "assert train_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label.max() == 1\n",
        "\n",
        "assert val_data[\"user\", \"listened_to_artist\", \"artist\"].num_edges == 272292\n",
        "assert val_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label_index.size(1) == 102108\n",
        "assert val_data[\"artist\", \"rev_listened_to_artist\", \"user\"].num_edges == 272292\n",
        "# Negative edges with ratio 2:1:\n",
        "assert val_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label.long().bincount().tolist() == [68072, 34036]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb98c651-674c-4465-cb94-89cf96ba21ba",
        "id": "0MYS_VALNjiW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data:\n",
            "==============\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[196],\n",
            "    x=[196, 47],\n",
            "  },\n",
            "  artist={ node_id=[340364] },\n",
            "  (user, listened_to_artist, artist)={\n",
            "    edge_index=[2, 190605],\n",
            "    edge_label=[81687],\n",
            "    edge_label_index=[2, 81687],\n",
            "  },\n",
            "  (artist, rev_listened_to_artist, user)={ edge_index=[2, 190605] }\n",
            ")\n",
            "\n",
            "Validation data:\n",
            "================\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[196],\n",
            "    x=[196, 47],\n",
            "  },\n",
            "  artist={ node_id=[340364] },\n",
            "  (user, listened_to_artist, artist)={\n",
            "    edge_index=[2, 272292],\n",
            "    edge_label=[102108],\n",
            "    edge_label_index=[2, 102108],\n",
            "  },\n",
            "  (artist, rev_listened_to_artist, user)={ edge_index=[2, 272292] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Mini-batch Loaders"
      ],
      "metadata": {
        "id": "wYIFje7pNjiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In the first hop, we sample at most 20 neighbors.\n",
        "# firs hop: 20 neighbours\n",
        "# In the second hop, we sample at most 10 neighbors.\n",
        "# second hop: 10 neighbours\n",
        "# During training, negative edges are sampled on-the-fly with a ratio of 2:1.\n",
        "\n",
        "# Define seed edges:\n",
        "edge_label_index = train_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label_index\n",
        "edge_label = train_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label\n",
        "\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,\n",
        "    num_neighbors=[20, 10],\n",
        "    neg_sampling_ratio=2.0,\n",
        "    edge_label_index=((\"user\", \"listened_to_artist\", \"artist\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Inspect a sample:\n",
        "sampled_data = next(iter(train_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label.min() == 0\n",
        "assert sampled_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label.max() == 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30ddbb3-7ed7-4154-c488-279645f41d50",
        "id": "9v5uun7jNjiW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[195],\n",
            "    x=[195, 47],\n",
            "    n_id=[195],\n",
            "    num_sampled_nodes=[3],\n",
            "  },\n",
            "  artist={\n",
            "    node_id=[2212],\n",
            "    n_id=[2212],\n",
            "    num_sampled_nodes=[3],\n",
            "  },\n",
            "  (user, listened_to_artist, artist)={\n",
            "    edge_index=[2, 15636],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    e_id=[15636],\n",
            "    num_sampled_edges=[2],\n",
            "    input_id=[128],\n",
            "  },\n",
            "  (artist, rev_listened_to_artist, user)={\n",
            "    edge_index=[2, 3336],\n",
            "    e_id=[3336],\n",
            "    num_sampled_edges=[2],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Heterogeneous Link-level GNN\n"
      ],
      "metadata": {
        "id": "Td0OdpFMNjiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, x_artist: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_artist = x_artist[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return (edge_feat_user * edge_feat_artist).sum(dim=-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and artist:\n",
        "        self.artist_lin = torch.nn.Linear(0, hidden_channels)\n",
        "        self.user_lin = torch.nn.Linear(47, hidden_channels)\n",
        "        self.artist_emb = torch.nn.Embedding(data_artist[\"artist\"].num_nodes, hidden_channels)\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data_artist.metadata())\n",
        "\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"user\": self.user_lin(data[\"user\"].x),\n",
        "          \"artist\": self.artist_emb(data[\"artist\"].node_id),\n",
        "        }\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"user\"],\n",
        "            x_dict[\"artist\"],\n",
        "            data[\"user\", \"listened_to_artist\", \"artist\"].edge_label_index,\n",
        "        )\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "model = Model(hidden_channels=64)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce73558b-66a7-4257-c8d6-12699c9abec7",
        "id": "MwxrU_8mNjiX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (artist_lin): Linear(in_features=0, out_features=128, bias=True)\n",
            "  (user_lin): Linear(in_features=47, out_features=128, bias=True)\n",
            "  (artist_emb): Embedding(340364, 128)\n",
            "  (gnn): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (user__listened_to_artist__artist): SAGEConv(128, 128, aggr=mean)\n",
            "      (artist__rev_listened_to_artist__user): SAGEConv(128, 128, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (user__listened_to_artist__artist): SAGEConv(128, 128, aggr=mean)\n",
            "      (artist__rev_listened_to_artist__user): SAGEConv(128, 128, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Classifier()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Heterogeneous Link-level GNN"
      ],
      "metadata": {
        "id": "tiPAZ6n6NjiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        sampled_data.to(device)\n",
        "        pred = model(sampled_data)\n",
        "\n",
        "        ground_truth = sampled_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148c4803-312a-470b-ff57-c90c4b00a0ff",
        "id": "wnWCrjXbNjiX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: 'cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:09<00:00, 69.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.1894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:09<00:00, 69.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.1280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:09<00:00, 66.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.1154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:08<00:00, 74.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.1029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 639/639 [00:09<00:00, 67.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Loss: 0.0910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating Heterogeneous Link-level GNN\n"
      ],
      "metadata": {
        "id": "TkLioPMFNjiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label_index\n",
        "edge_label = val_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,\n",
        "    num_neighbors=[20, 10],\n",
        "    edge_label_index=((\"user\", \"listened_to_artist\", \"artist\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "sampled_data = next(iter(val_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label.min() >= 0\n",
        "assert sampled_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label.max() <= 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb57b946-7651-4735-fc4f-a76fb8e00aa5",
        "id": "XaonNYQLNjiX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[188],\n",
            "    x=[188, 47],\n",
            "    n_id=[188],\n",
            "    num_sampled_nodes=[3],\n",
            "  },\n",
            "  artist={\n",
            "    node_id=[1918],\n",
            "    n_id=[1918],\n",
            "    num_sampled_nodes=[3],\n",
            "  },\n",
            "  (user, listened_to_artist, artist)={\n",
            "    edge_index=[2, 17051],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    e_id=[17051],\n",
            "    num_sampled_edges=[2],\n",
            "    input_id=[384],\n",
            "  },\n",
            "  (artist, rev_listened_to_artist, user)={\n",
            "    edge_index=[2, 2990],\n",
            "    e_id=[2990],\n",
            "    num_sampled_edges=[2],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "ground_truths = []\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        preds.append(model(sampled_data))\n",
        "        ground_truths.append(sampled_data[\"user\", \"listened_to_artist\", \"artist\"].edge_label)\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "\n",
        "# Calculate ROC-AUC\n",
        "auc = roc_auc_score(ground_truth, pred)\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n",
        "\n",
        "# Calculate Average Precision (AP)\n",
        "ap = average_precision_score(ground_truth, pred)\n",
        "print(f\"Average Precision (AP): {ap:.4f}\")\n",
        "\n",
        "# Calculate F1 score\n",
        "# First, we need to convert the probabilities to class labels (0 or 1)\n",
        "# We use 0.5 as the threshold\n",
        "pred_labels = (pred > 0.5).astype(int)\n",
        "f1 = f1_score(ground_truth, pred_labels)\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6eea26c-203c-429c-c85b-9406f80eabec",
        "id": "s_embjPiNjiX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 266/266 [00:01<00:00, 173.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation AUC: 0.9869\n",
            "Average Precision (AP): 0.9799\n",
            "F1 Score: 0.9525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQAi3AzNziyC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}